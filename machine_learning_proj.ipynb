{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/phubestp/Machine_Learning_Final_Project/blob/main/machine_learning_proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algerian Forest Fires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[dataset](https://archive.ics.uci.edu/dataset/547/algerian+forest+fires+dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes 244 instances that regroup a data of two regions of Algeria,namely the Bejaia region located in the northeast of Algeria and the Sidi Bel-abbes region located in the northwest of Algeria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "U0caEk_yJsGl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ml_lib.preprocessing import TrainTestSplit\n",
    "from ml_lib.knn import KNN\n",
    "from ml_lib.svm import SVM\n",
    "from ml_lib.logistic_regression import LogisticRegression\n",
    "from ml_lib.naive_bayes import GaussianNaiveBayes\n",
    "from ml_lib.accuracy import Accuracy\n",
    "from ml_lib.perceptron import Perceptron\n",
    "from ml_lib.scaler import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 244 entries, 0 to 243\n",
      "Data columns (total 14 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   day          244 non-null    int64  \n",
      " 1   month        244 non-null    int64  \n",
      " 2   year         244 non-null    int64  \n",
      " 3   Temperature  244 non-null    int64  \n",
      " 4   RH           244 non-null    int64  \n",
      " 5   Ws           244 non-null    int64  \n",
      " 6   Rain         244 non-null    float64\n",
      " 7   FFMC         244 non-null    float64\n",
      " 8   DMC          244 non-null    float64\n",
      " 9   DC           244 non-null    float64\n",
      " 10  ISI          244 non-null    float64\n",
      " 11  BUI          244 non-null    float64\n",
      " 12  FWI          244 non-null    float64\n",
      " 13  Classes      244 non-null    object \n",
      "dtypes: float64(7), int64(6), object(1)\n",
      "memory usage: 26.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\",skipinitialspace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      notfire\n",
       "1      notfire\n",
       "2      notfire\n",
       "3      notfire\n",
       "4      notfire\n",
       "        ...   \n",
       "239       fire\n",
       "240    notfire\n",
       "241    notfire\n",
       "242    notfire\n",
       "243    notfire\n",
       "Name: Classes, Length: 244, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Classes'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "split = TrainTestSplit()\n",
    "\n",
    "X = data.drop(['Classes', 'day', 'month', 'year'], axis=1)\n",
    "y = data['Classes'].replace({\"notfire\":-1, \"fire\":1})\n",
    "X = scaler.scale(np.array(X))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split.train_test_split(X, y) #default = test_size=0.33, random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN (K-nearest neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9384615384615385"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNN(10, 2)\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)\n",
    "accuracy.score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -5.7          0.2173913   -4.17391304   7.02380952  20.02077151\n",
      "   -8.9892638    8.24918033  26.45263158  -5.64723468  25.18971061\n",
      "  -17.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9692307692307692"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron(X_train.shape[1])\n",
    "perceptron.fit(X_train, y_train)\n",
    "pred = perceptron.predict(X_test)\n",
    "accuracy.score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (Gaussian Naive Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8769230769230769"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNaiveBayes()\n",
    "nb.fit(X_train, y_train)\n",
    "pred = nb.predict(X_test)\n",
    "accuracy.score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076923076923077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVM(X_train.shape[1], 10)\n",
    "svm.fit(X_train, y_train)\n",
    "pred = svm.predict(X_test)\n",
    "accuracy.score(pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9384615384615385"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(X_train.shape[1])\n",
    "lr.fit(X_train, y_train)\n",
    "pred = lr.predict(X_test)\n",
    "accuracy.score(pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP7Y+N+0wySlQKsTJPEfss/",
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
